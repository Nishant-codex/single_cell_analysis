{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nishant Joshi\\anaconda3\\lib\\site-packages\\umap\\distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "c:\\Users\\Nishant Joshi\\anaconda3\\lib\\site-packages\\umap\\distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "c:\\Users\\Nishant Joshi\\anaconda3\\lib\\site-packages\\umap\\distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "c:\\Users\\Nishant Joshi\\anaconda3\\lib\\site-packages\\umap\\umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "c:\\Users\\Nishant Joshi\\anaconda3\\lib\\site-packages\\umap\\plot.py:203: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "#@title imports \n",
    "import os\n",
    "import pickle\n",
    "from typing import Set\n",
    "# from jedi import settings\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.lib.function_base import append \n",
    "import scipy.io as spio\n",
    "from scipy.io import loadmat, savemat\n",
    "from sklearn import datasets, linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import data \n",
    "import pandas as pd \n",
    "import matplotlib as mpl \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import SparsePCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from sklearn import manifold, datasets\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap.plot as uplot\n",
    "from sknetwork.clustering import Louvain,get_modularity\n",
    "from sknetwork.data import karate_club\n",
    "import sys \n",
    "sys.path.append('C:/Users/Nishant Joshi/Downloads/Old_code/repo/single_cell_analysis/scripts')\n",
    "from sknetwork.clustering import Louvain,get_modularity\n",
    "from sknetwork.data import karate_club\n",
    "from UMAP import *\n",
    "pd.options.mode.use_inf_as_na = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAABICAYAAACJB+2oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAACQ0lEQVR4nO3aPWpUURzG4feYoBMYIcJokSadWImge7AQGwsbG4vgLrIAt2AlgmuwFFuZ0mawsEqwiF+IX9VxA8kkzbkn9+Z52sPA+6/mFyal1hoA4GK71HsAANCfIAAABAEAIAgAgAgCACCCAABIsrnucTbbrvP5zlBbBvdl8bv3hKbulqPeE5r6+/FK7wnNzG786T2hqYPFrd4Tmvr8Y9p/a93Z+NV7QlP/ttZ+NY7a4eFBvn/7Wo57W3v1fL6TBw9ft1l1DrzaW/ae0NTy8sveE5pa3d/tPaGZm88+9J7Q1P7Td70nNPX8zdXeE5p6u/2+94SmPt2+1ntCM08ePzrxbdoZCwCciSAAAAQBACAIAIAIAgAgggAAiCAAACIIAIAIAgAgggAAiCAAACIIAIAIAgAgggAAiCAAACIIAIAIAgAgggAAiCAAACIIAIAIAgAgggAAiCAAACIIAIAIAgAgggAAiCAAACIIAIAIAgAgggAAiCAAACIIAIAIAgAgggAAiCAAACIIAIAIAgAgggAAiCAAACIIAIAIAgAgggAAiCAAACIIAIAIAgAgggAAiCAAACIIAIAIAgAgggAAiCAAACIIAIAkpdZ68mMpP5OshpszuEWSo94jGnLfeE35tsR9Y+e+8dqttV4/7mHzlA+uaq33Ggw6F0opS/eN15Tvm/JtifvGzn3T5CcDAEAQAACnB8GLQVb0475xm/J9U74tcd/YuW+C1v5TIQBwMfjJAAAQBACAIAAAIggAgAgCACDJf8dTX/ZM8yt9AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 648x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAABICAYAAAAanHLSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAABoklEQVR4nO3YPUoDURiF4TsmYy9oFYKVjWCX0m24L2u3kMItCFraq7XYSSyMlcp1A/nBYmZywvO0l8D5iheGNLXWAuQ4GHoA8D+ihTCihTCihTCihTCihTDjTY9Ho1GdtG1fW3r3fHY49IROXfwsh57Qqafl+dATOvO9eCu/Xx/NqreN0U7atsyn025W7YDL2/29rZRS7hYPQ0/o1Ox+PvSEzrxeX61983kMYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYZpa6/rHpvkspbz0N6d3x6WU96FHdMh9uU5rrSerHsZbfvhSa511MGgnNE3z6L5c+37fOj6PIYxoIcy2aG96WTEc92Xb9/tW2vhHFLB7fB5DGNFCGNFCGNFCGNFCmD+s4TfrH4LWSAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 288x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAABICAYAAADyIy9kAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAChklEQVR4nO3cMWpUURiG4XPjJDgEUUhCiIJWNmIlguB6XEaKVNmAnZWdYGWRFVhbC1MGRBQGSdBCTPBkA8lMde7J/Xie9hD4/u6FO2SotRYAgGQbvQcAALQmeACAeIIHAIgneACAeIIHAIgneACAeLNVj/e27ted+f5YW0b3a+Oi94Sm6uad3hOaudye957Q1PbWWe8JTT26WPae0Naf3gPauvy32XtCM7OHf3tPaOr8+9PeE5o6Pf+6rLXuXfe2Mnh25vvl8PXbNqtugQ93f/ae0NT/gwe9JzSzfPWs94SmXjz+1HtCU8c/3vee0Nbn7P9vdvbtoPeEZnaPFr0nNHVy9LH3hKbenDw/venNJy0AIJ7gAQDiCR4AIJ7gAQDiCR4AIJ7gAQDiCR4AIJ7gAQDiCR4AIJ7gAQDiCR4AIJ7gAQDiCR4AIJ7gAQDiCR4AIJ7gAQDiCR4AIJ7gAQDiCR4AIJ7gAQDiCR4AIJ7gAQDiCR4AIJ7gAQDiCR4AIJ7gAQDiCR4AIJ7gAQDiCR4AIJ7gAQDiCR4AIJ7gAQDiCR4AIJ7gAQDiCR4AIJ7gAQDiCR4AIJ7gAQDiCR4AIJ7gAQDiCR4AIJ7gAQDiCR4AIJ7gAQDiCR4AIJ7gAQDiCR4AIJ7gAQDiCR4AIJ7gAQDiCR4AIJ7gAQDiDbXWmx+H4XcpZTHenNHtllKWvUc05L7pSr6tFPdNnfumK/m2Ukp5Umvdu+5htuYPF7XWlw0G3QrDMHxx33Ql35d8Wynumzr3TVfybev4pAUAxBM8AEC8dcHzbpQV/bhv2pLvS76tFPdNnfumK/m2lVb+aBkAIIFPWgBAPMEDAMQTPABAPMEDAMQTPABAvCsoOmxNTDqGHgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "CUSTOM_PAL_SORT_3 = ['#5e60ce','#00c49a','#ffca3a','#D81159','#fe7f2d','#7bdff2','#0496ff','#efa6c9','#ced4da']\n",
    "GMM_PAL = ['#d62424','#12db41','#f0c905','#248cd6']\n",
    "\n",
    "# In RGB form\n",
    "coherence_colors = [[0.609, 0.283, 0.724],\n",
    "                    [0.259,\t0.314, 0.635],\n",
    "                    [0.251,\t0.412, 0.698],\n",
    "                    [0.176,\t0.631, 0.859],\n",
    "                    [0.369,\t0.749, 0.549],\n",
    "                    [0.898,\t0.654, 0.169],\n",
    "                    [0.898,\t0.41 , 0.165],\n",
    "                    [0.834,\t0.3 , 0.265],\n",
    "                    [0.912,\t0.8 , 0.112],\n",
    "                    [0.612,\t0.3 , 0.834]]\n",
    "sns.palplot(CUSTOM_PAL_SORT_3)\n",
    "sns.palplot(GMM_PAL)\n",
    "sns.palplot(coherence_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_UMAP_clusters_single(data_inh, neighbours, distance, res_louvain, random_state, c_list ,save=False):\n",
    "    \"\"\"plots UMAP for excitatory and inhibitory cells \n",
    "\n",
    "    Args:\n",
    "        data_inh (ndarray): cell X feature matrix for inhibitory cells\n",
    "        data_exc (ndarray): cell X feature matrix for excitatory cells\n",
    "        c_exc (array): _description_\n",
    "        c_inh (array): _description_\n",
    "        neighbours (int): number of neares neighbours\n",
    "        distance (float): minimum distance between points\n",
    "    \"\"\"\n",
    "    data_umap_scaler = StandardScaler()\n",
    "    data_umap = data_umap_scaler.fit_transform(data_inh)\n",
    "    # data_umap = normalize(data_umap)\n",
    " \n",
    "    neighbours = neighbours\n",
    "    dist = distance\n",
    "    reducer = umap.UMAP(n_neighbors=neighbours,min_dist=dist,random_state=random_state)\n",
    "    mapper = reducer.fit(data_umap)\n",
    "    \n",
    "    fig = plt.figure(figsize=[8,8])\n",
    "    ax12d = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    louvain = Louvain(resolution=res_louvain,random_state=random_state)\n",
    "    adjacency = mapper.graph_\n",
    "    labels_exc = louvain.fit_predict(adjacency)\n",
    "\n",
    "    print(len(set(labels_exc)))\n",
    "    clusterable_embedding2d_exc = umap.UMAP(n_neighbors=neighbours,min_dist=dist,\n",
    "        n_components=2,random_state=random_state,).fit_transform(data_umap)\n",
    "\n",
    "\n",
    "\n",
    "    df_2d_exc = {'UMAP1':clusterable_embedding2d_exc[:, 0],\n",
    "             'UMAP2':clusterable_embedding2d_exc[:, 1],\n",
    "             'class':labels_exc}\n",
    "\n",
    "    ax12d.set_xticks([])\n",
    "    ax12d.set_yticks([])\n",
    "\n",
    "    sns.scatterplot(data=df_2d_exc,x='UMAP1',y='UMAP2',hue='class',palette=c_list[:len(set(labels_exc))],ax=ax12d)\n",
    "    # sns.scatterplot(data=df_2d_exc,x='UMAP1',y='UMAP2',hue='class',ax=ax12d)\n",
    "\n",
    "    # ax12d.set_title('UMAP clusters for excitatory neurons 2D')\n",
    "    ax12d.legend()\n",
    "    if save:\n",
    "        plt.savefig('C:/Users/Nishant Joshi/Documents/DNM/exc_umap_cluster.png',dpi=200)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    return labels_exc,mapper,reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pal = [\"#00202e\",\"#003f5c\",\"#2c4875\",\"#8a508f\",\"#bc5090\",\"#ff6361\",\"#ff8531\",\"#ffa600\",\"#ffd380\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_ext = ['current_at_first_spike','ap_count','fr','inst_fr','time_to_first_spike','mean_isi','median_isi','max_isi',\n",
    "'min_isi','first_thr','mean_thr','median_thr','min_thr','max_thr','mean_width','median_width','max_width',\n",
    "'min_width','mean_amplitude','median_amplitude','min_amplitude','max_amplitude','exp_name','cond','trialnr']\n",
    "features_ext_sub = ['current_at_first_spike','ap_count','fr','inst_fr','time_to_first_spike','mean_isi','median_isi','max_isi',\n",
    "'min_isi','first_thr','mean_thr','median_thr','min_thr','max_thr','mean_width','median_width','max_width',\n",
    "'min_width','mean_amplitude','median_amplitude','min_amplitude','max_amplitude']\n",
    "data_all_conds = pickle.load(open('G:/My Drive/Cluster Feature files/Niccolo_FN.pkl','rb'))\n",
    "exc = data_all_conds['exc']\n",
    "inh = data_all_conds['inh']\n",
    "def lower(data):\n",
    "    return data.lower()\n",
    "exc_df_all = pd.DataFrame(exc,columns = features_ext)\n",
    "inh_df_all = pd.DataFrame(inh,columns = features_ext)\n",
    "exc_inh_df = pd.concat([exc_df_all,inh_df_all])\n",
    "exc_inh_df.index = np.arange(len(exc_inh_df))\n",
    "inds =set(np.where(exc_inh_df.isna())[0])\n",
    "\n",
    "exc_inh_df['ei_labels'] = np.concatenate((np.repeat(0,len(exc_df_all)),np.repeat(1,len(inh_df_all))))\n",
    "exc_inh_df = exc_inh_df.drop(inds,axis=0)\n",
    "\n",
    "exc_inh_df.cond = exc_inh_df.cond.apply(lower)    \n",
    "exc_inh_df_acsf = exc_inh_df[exc_inh_df.cond=='acsf'] \n",
    "NC_data  = exc_inh_df_acsf[ exc_inh_df_acsf.exp_name.isin(exc_inh_df_acsf.exp_name[['NC' in i for i in exc_inh_df_acsf.exp_name]])]\n",
    "NC_data1= NC_data[NC_data.trialnr==1]\n",
    "NC_data1 = NC_data1.drop_duplicates('exp_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_name_string_obj_NC(data):\n",
    "  broken_str = data.split('_')\n",
    "  if 'NC' == broken_str[2]:\n",
    "    name = broken_str[2]\n",
    "    date = broken_str[3]\n",
    "    return name+'_'+date\n",
    "  else:\n",
    "    name = broken_str[3]\n",
    "    date = broken_str[2]\n",
    "    return name+'_'+date\n",
    "\n",
    "def modify_names(file_name):\n",
    "  str_temp = file_name\n",
    "  all_parts = str_temp.split('_')\n",
    "  print(all_parts)\n",
    "  name = all_parts[0]\n",
    "  if 'Payam' == name:\n",
    "    name = name.lower()\n",
    "  broken = all_parts[1].split('-')\n",
    "  date = broken[:3]\n",
    "  date = date[0]+date[1]+date[2]\n",
    "  exp = broken[3]\n",
    "  return name+'_'+date+'_'+exp\n",
    "\n",
    "def return_name_date_exp_fn(string):\n",
    "\n",
    "  if 'NC' in string:\n",
    "    string_broken = string.split('_')\n",
    "    name = string_broken[0]\n",
    "    date = string_broken[1]\n",
    "    exp = string_broken[-1]\n",
    "    year = date[:2]\n",
    "    month = date[2:4]\n",
    "\n",
    "    if month[0] =='0':\n",
    "      month = month[1]\n",
    "    day = date[4:]\n",
    "    if day[0] =='0':\n",
    "      day = day[1]\n",
    "    date = day+month+year  \n",
    "    return name+'_'+date+'_'+exp \n",
    "  elif 'xuan' in string:\n",
    "    broken_str = string.split('_')\n",
    "    name = broken_str[0]\n",
    "    date = broken_str[1].replace('-','')\n",
    "    exp =  broken_str[2]\n",
    "    return name+'_'+date+'_'+exp\n",
    "  elif 'asli' in string:\n",
    "    broken_str = string.split('_')\n",
    "    name = broken_str[0]\n",
    "    date = broken_str[1].replace('-','')\n",
    "    exp =  broken_str[2]\n",
    "    return name+'_'+date+'_'+exp    \n",
    "  elif 'Payam' in string:\n",
    "    broken_str = string.split('_')\n",
    "    name = broken_str[0].lower()\n",
    "    date = broken_str[1].split('-')\n",
    "    exp =  broken_str[2]\n",
    "    day = date[0]\n",
    "    month = date[1]\n",
    "    year = date[2]\n",
    "    if day[0] =='0':\n",
    "      day=day[1]\n",
    "    date = day+month+year  \n",
    "    return name+'_'+date+'_'+exp\n",
    "\n",
    "all_cc_names_and_dates = [return_name_date_exp_fn(i) for i in exc_inh_df_acsf.exp_name]\n",
    "\n",
    "# modify_names(exc_inh_df_acsf.exp_name[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nishant Joshi\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "exc_inh_df_acsf.exp_name = exc_inh_df_acsf.exp_name.apply(return_name_date_exp_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_at_first_spike</th>\n",
       "      <th>ap_count</th>\n",
       "      <th>fr</th>\n",
       "      <th>inst_fr</th>\n",
       "      <th>time_to_first_spike</th>\n",
       "      <th>mean_isi</th>\n",
       "      <th>median_isi</th>\n",
       "      <th>max_isi</th>\n",
       "      <th>min_isi</th>\n",
       "      <th>first_thr</th>\n",
       "      <th>...</th>\n",
       "      <th>max_width</th>\n",
       "      <th>min_width</th>\n",
       "      <th>mean_amplitude</th>\n",
       "      <th>median_amplitude</th>\n",
       "      <th>min_amplitude</th>\n",
       "      <th>max_amplitude</th>\n",
       "      <th>exp_name</th>\n",
       "      <th>cond</th>\n",
       "      <th>trialnr</th>\n",
       "      <th>ei_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.200875</td>\n",
       "      <td>291</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.046849</td>\n",
       "      <td>2703.35</td>\n",
       "      <td>1224.064483</td>\n",
       "      <td>274.25</td>\n",
       "      <td>15331.60</td>\n",
       "      <td>6.45</td>\n",
       "      <td>-44.218749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.075</td>\n",
       "      <td>84.861815</td>\n",
       "      <td>90.718750</td>\n",
       "      <td>51.062500</td>\n",
       "      <td>132.343750</td>\n",
       "      <td>NC_11717_E1</td>\n",
       "      <td>acsf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>239.102574</td>\n",
       "      <td>177</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.037377</td>\n",
       "      <td>2698.60</td>\n",
       "      <td>2010.438920</td>\n",
       "      <td>772.70</td>\n",
       "      <td>18273.45</td>\n",
       "      <td>6.30</td>\n",
       "      <td>-39.593749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.450</td>\n",
       "      <td>83.459774</td>\n",
       "      <td>89.343748</td>\n",
       "      <td>51.187498</td>\n",
       "      <td>98.468751</td>\n",
       "      <td>NC_11717_E1</td>\n",
       "      <td>acsf</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>144.071654</td>\n",
       "      <td>433</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>0.014939</td>\n",
       "      <td>1819.10</td>\n",
       "      <td>825.283449</td>\n",
       "      <td>477.60</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>7.60</td>\n",
       "      <td>-40.937498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.425</td>\n",
       "      <td>86.679612</td>\n",
       "      <td>89.062499</td>\n",
       "      <td>33.812500</td>\n",
       "      <td>112.124998</td>\n",
       "      <td>NC_11717_E2</td>\n",
       "      <td>acsf</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>196.910798</td>\n",
       "      <td>127</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.005651</td>\n",
       "      <td>8316.55</td>\n",
       "      <td>2772.755159</td>\n",
       "      <td>1818.25</td>\n",
       "      <td>15337.05</td>\n",
       "      <td>15.15</td>\n",
       "      <td>-36.125001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.575</td>\n",
       "      <td>84.804981</td>\n",
       "      <td>86.218748</td>\n",
       "      <td>56.250000</td>\n",
       "      <td>103.874996</td>\n",
       "      <td>NC_12717_E1</td>\n",
       "      <td>acsf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>136.330819</td>\n",
       "      <td>171</td>\n",
       "      <td>1.870000</td>\n",
       "      <td>0.032204</td>\n",
       "      <td>2101.80</td>\n",
       "      <td>2103.784412</td>\n",
       "      <td>1570.90</td>\n",
       "      <td>16483.80</td>\n",
       "      <td>4.10</td>\n",
       "      <td>-27.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.450</td>\n",
       "      <td>0.125</td>\n",
       "      <td>66.987582</td>\n",
       "      <td>70.656250</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>115.999997</td>\n",
       "      <td>NC_12717_E2</td>\n",
       "      <td>acsf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>159.357426</td>\n",
       "      <td>6183</td>\n",
       "      <td>17.227778</td>\n",
       "      <td>0.059214</td>\n",
       "      <td>170.65</td>\n",
       "      <td>58.203551</td>\n",
       "      <td>21.80</td>\n",
       "      <td>956.15</td>\n",
       "      <td>4.55</td>\n",
       "      <td>-46.093751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.225</td>\n",
       "      <td>86.039846</td>\n",
       "      <td>90.390626</td>\n",
       "      <td>33.093750</td>\n",
       "      <td>146.499999</td>\n",
       "      <td>xuan_9519_E1</td>\n",
       "      <td>acsf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>210.442570</td>\n",
       "      <td>430</td>\n",
       "      <td>1.194444</td>\n",
       "      <td>0.007305</td>\n",
       "      <td>1901.25</td>\n",
       "      <td>834.697319</td>\n",
       "      <td>552.20</td>\n",
       "      <td>5152.95</td>\n",
       "      <td>8.40</td>\n",
       "      <td>-42.624999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.150</td>\n",
       "      <td>101.515770</td>\n",
       "      <td>101.093749</td>\n",
       "      <td>80.781251</td>\n",
       "      <td>111.906253</td>\n",
       "      <td>xuan_9519_E3</td>\n",
       "      <td>acsf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>251.319290</td>\n",
       "      <td>3260</td>\n",
       "      <td>9.111111</td>\n",
       "      <td>0.044225</td>\n",
       "      <td>173.50</td>\n",
       "      <td>110.405769</td>\n",
       "      <td>37.80</td>\n",
       "      <td>1586.60</td>\n",
       "      <td>5.10</td>\n",
       "      <td>-30.062500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.250</td>\n",
       "      <td>78.526038</td>\n",
       "      <td>83.500000</td>\n",
       "      <td>27.531249</td>\n",
       "      <td>137.281250</td>\n",
       "      <td>xuan_9919_E1</td>\n",
       "      <td>acsf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>24.907842</td>\n",
       "      <td>864</td>\n",
       "      <td>2.402778</td>\n",
       "      <td>0.016246</td>\n",
       "      <td>1563.10</td>\n",
       "      <td>415.320568</td>\n",
       "      <td>228.40</td>\n",
       "      <td>3302.75</td>\n",
       "      <td>4.95</td>\n",
       "      <td>-43.218751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.150</td>\n",
       "      <td>108.289632</td>\n",
       "      <td>108.562503</td>\n",
       "      <td>83.281249</td>\n",
       "      <td>144.468747</td>\n",
       "      <td>xuan_9919_E3</td>\n",
       "      <td>acsf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>299.837364</td>\n",
       "      <td>4174</td>\n",
       "      <td>11.594444</td>\n",
       "      <td>0.045691</td>\n",
       "      <td>172.40</td>\n",
       "      <td>86.223940</td>\n",
       "      <td>34.80</td>\n",
       "      <td>1207.90</td>\n",
       "      <td>4.05</td>\n",
       "      <td>-44.406250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.225</td>\n",
       "      <td>86.999057</td>\n",
       "      <td>87.500002</td>\n",
       "      <td>61.156249</td>\n",
       "      <td>106.906250</td>\n",
       "      <td>xuan_9919_E4</td>\n",
       "      <td>acsf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     current_at_first_spike  ap_count         fr   inst_fr  \\\n",
       "0                  8.200875       291   0.887500  0.046849   \n",
       "1                239.102574       177   0.590000  0.037377   \n",
       "2                144.071654       433   1.560000  0.014939   \n",
       "4                196.910798       127   0.383333  0.005651   \n",
       "5                136.330819       171   1.870000  0.032204   \n",
       "..                      ...       ...        ...       ...   \n",
       "873              159.357426      6183  17.227778  0.059214   \n",
       "875              210.442570       430   1.194444  0.007305   \n",
       "877              251.319290      3260   9.111111  0.044225   \n",
       "880               24.907842       864   2.402778  0.016246   \n",
       "883              299.837364      4174  11.594444  0.045691   \n",
       "\n",
       "     time_to_first_spike     mean_isi  median_isi   max_isi  min_isi  \\\n",
       "0                2703.35  1224.064483      274.25  15331.60     6.45   \n",
       "1                2698.60  2010.438920      772.70  18273.45     6.30   \n",
       "2                1819.10   825.283449      477.60   6183.95     7.60   \n",
       "4                8316.55  2772.755159     1818.25  15337.05    15.15   \n",
       "5                2101.80  2103.784412     1570.90  16483.80     4.10   \n",
       "..                   ...          ...         ...       ...      ...   \n",
       "873               170.65    58.203551       21.80    956.15     4.55   \n",
       "875              1901.25   834.697319      552.20   5152.95     8.40   \n",
       "877               173.50   110.405769       37.80   1586.60     5.10   \n",
       "880              1563.10   415.320568      228.40   3302.75     4.95   \n",
       "883               172.40    86.223940       34.80   1207.90     4.05   \n",
       "\n",
       "     first_thr  ...  max_width  min_width  mean_amplitude  median_amplitude  \\\n",
       "0   -44.218749  ...      0.975      0.075       84.861815         90.718750   \n",
       "1   -39.593749  ...      0.925      0.450       83.459774         89.343748   \n",
       "2   -40.937498  ...      0.725      0.425       86.679612         89.062499   \n",
       "4   -36.125001  ...      0.950      0.575       84.804981         86.218748   \n",
       "5   -27.500000  ...      1.450      0.125       66.987582         70.656250   \n",
       "..         ...  ...        ...        ...             ...               ...   \n",
       "873 -46.093751  ...      0.325      0.225       86.039846         90.390626   \n",
       "875 -42.624999  ...      0.250      0.150      101.515770        101.093749   \n",
       "877 -30.062500  ...      0.400      0.250       78.526038         83.500000   \n",
       "880 -43.218751  ...      0.225      0.150      108.289632        108.562503   \n",
       "883 -44.406250  ...      0.300      0.225       86.999057         87.500002   \n",
       "\n",
       "     min_amplitude  max_amplitude      exp_name  cond  trialnr  ei_labels  \n",
       "0        51.062500     132.343750   NC_11717_E1  acsf        1          0  \n",
       "1        51.187498      98.468751   NC_11717_E1  acsf        2          0  \n",
       "2        33.812500     112.124998   NC_11717_E2  acsf        2          0  \n",
       "4        56.250000     103.874996   NC_12717_E1  acsf        1          0  \n",
       "5         4.750000     115.999997   NC_12717_E2  acsf        1          0  \n",
       "..             ...            ...           ...   ...      ...        ...  \n",
       "873      33.093750     146.499999  xuan_9519_E1  acsf        1          1  \n",
       "875      80.781251     111.906253  xuan_9519_E3  acsf        1          1  \n",
       "877      27.531249     137.281250  xuan_9919_E1  acsf        1          1  \n",
       "880      83.281249     144.468747  xuan_9919_E3  acsf        1          1  \n",
       "883      61.156249     106.906250  xuan_9919_E4  acsf        1          1  \n",
       "\n",
       "[470 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exc_inh_df_acsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/Nishant Joshi/Downloads/CC_exps_clust.csv')\n",
    "feats = ['current_first_spike','ap_count','abs_firing_rate',\n",
    "        'inst_firing_rate','time_to_first_spike','mean_isi','max_isi',\n",
    "        'min_isi','median_isi','first_thrs','mean_thrs',\n",
    "        'max_thrs','min_thrs','median_thrs','first_hwidths','mean_hwidths',\n",
    "        'median_hwidths','max_hwidths','min_hwidths','first_amp',\n",
    "        'mean_amp','median_amp','max_amp','min_amp','condtition',\n",
    "        'drug','exp_name','classification','trial']\n",
    "data =  data[feats]\n",
    "data_inh = data[data.classification=='inhibitory']\n",
    "data_exc = data[data.classification=='excitatory']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_first_spike</th>\n",
       "      <th>ap_count</th>\n",
       "      <th>abs_firing_rate</th>\n",
       "      <th>inst_firing_rate</th>\n",
       "      <th>time_to_first_spike</th>\n",
       "      <th>mean_isi</th>\n",
       "      <th>max_isi</th>\n",
       "      <th>min_isi</th>\n",
       "      <th>median_isi</th>\n",
       "      <th>first_thrs</th>\n",
       "      <th>...</th>\n",
       "      <th>first_amp</th>\n",
       "      <th>mean_amp</th>\n",
       "      <th>median_amp</th>\n",
       "      <th>max_amp</th>\n",
       "      <th>min_amp</th>\n",
       "      <th>condtition</th>\n",
       "      <th>drug</th>\n",
       "      <th>exp_name</th>\n",
       "      <th>classification</th>\n",
       "      <th>trial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.220000e-10</td>\n",
       "      <td>16</td>\n",
       "      <td>0.032003</td>\n",
       "      <td>0.044065</td>\n",
       "      <td>65.30</td>\n",
       "      <td>29.936667</td>\n",
       "      <td>42.50</td>\n",
       "      <td>8.05</td>\n",
       "      <td>34.450</td>\n",
       "      <td>-0.023906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111687</td>\n",
       "      <td>0.102479</td>\n",
       "      <td>0.107500</td>\n",
       "      <td>0.111687</td>\n",
       "      <td>0.088250</td>\n",
       "      <td>D2</td>\n",
       "      <td>False</td>\n",
       "      <td>xuan_231018_E1</td>\n",
       "      <td>excitatory</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.220000e-10</td>\n",
       "      <td>12</td>\n",
       "      <td>0.024002</td>\n",
       "      <td>0.031750</td>\n",
       "      <td>117.30</td>\n",
       "      <td>43.931818</td>\n",
       "      <td>67.85</td>\n",
       "      <td>11.05</td>\n",
       "      <td>52.700</td>\n",
       "      <td>-0.031313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095406</td>\n",
       "      <td>0.095406</td>\n",
       "      <td>0.095406</td>\n",
       "      <td>0.095406</td>\n",
       "      <td>0.095406</td>\n",
       "      <td>D2</td>\n",
       "      <td>False</td>\n",
       "      <td>xuan_231118_E2</td>\n",
       "      <td>excitatory</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.620000e-10</td>\n",
       "      <td>16</td>\n",
       "      <td>0.032003</td>\n",
       "      <td>0.055015</td>\n",
       "      <td>76.40</td>\n",
       "      <td>28.526667</td>\n",
       "      <td>78.25</td>\n",
       "      <td>8.85</td>\n",
       "      <td>17.700</td>\n",
       "      <td>-0.010969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109688</td>\n",
       "      <td>0.093625</td>\n",
       "      <td>0.090625</td>\n",
       "      <td>0.109688</td>\n",
       "      <td>0.088063</td>\n",
       "      <td>D2</td>\n",
       "      <td>False</td>\n",
       "      <td>xuan_26319_E2</td>\n",
       "      <td>excitatory</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.210000e-10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.016002</td>\n",
       "      <td>0.019330</td>\n",
       "      <td>86.95</td>\n",
       "      <td>61.935714</td>\n",
       "      <td>89.85</td>\n",
       "      <td>22.30</td>\n",
       "      <td>62.800</td>\n",
       "      <td>-0.038187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083375</td>\n",
       "      <td>0.078828</td>\n",
       "      <td>0.078828</td>\n",
       "      <td>0.083375</td>\n",
       "      <td>0.074281</td>\n",
       "      <td>D2</td>\n",
       "      <td>False</td>\n",
       "      <td>xuan_26319_E4</td>\n",
       "      <td>excitatory</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.020000e-10</td>\n",
       "      <td>51</td>\n",
       "      <td>0.102010</td>\n",
       "      <td>0.102468</td>\n",
       "      <td>16.90</td>\n",
       "      <td>9.815000</td>\n",
       "      <td>10.75</td>\n",
       "      <td>6.70</td>\n",
       "      <td>9.900</td>\n",
       "      <td>-0.048063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.091615</td>\n",
       "      <td>0.091406</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.086031</td>\n",
       "      <td>5HT-1f(S1 cortex)</td>\n",
       "      <td>False</td>\n",
       "      <td>xuan_26619_E6</td>\n",
       "      <td>inhibitory</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1.610000e-10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010001</td>\n",
       "      <td>0.050318</td>\n",
       "      <td>56.00</td>\n",
       "      <td>43.812500</td>\n",
       "      <td>75.90</td>\n",
       "      <td>8.80</td>\n",
       "      <td>45.275</td>\n",
       "      <td>-0.040063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093062</td>\n",
       "      <td>0.093062</td>\n",
       "      <td>0.093062</td>\n",
       "      <td>0.093062</td>\n",
       "      <td>0.093062</td>\n",
       "      <td>D2</td>\n",
       "      <td>False</td>\n",
       "      <td>xuan_17119_E3</td>\n",
       "      <td>excitatory</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>8.170000e-11</td>\n",
       "      <td>61</td>\n",
       "      <td>0.122012</td>\n",
       "      <td>0.122809</td>\n",
       "      <td>17.95</td>\n",
       "      <td>8.190833</td>\n",
       "      <td>8.85</td>\n",
       "      <td>5.30</td>\n",
       "      <td>8.350</td>\n",
       "      <td>-0.055563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122219</td>\n",
       "      <td>0.122219</td>\n",
       "      <td>0.122219</td>\n",
       "      <td>0.122219</td>\n",
       "      <td>0.122219</td>\n",
       "      <td>Alpha1</td>\n",
       "      <td>False</td>\n",
       "      <td>xuan_20919_E1</td>\n",
       "      <td>inhibitory</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1.220000e-10</td>\n",
       "      <td>15</td>\n",
       "      <td>0.030003</td>\n",
       "      <td>0.034610</td>\n",
       "      <td>44.40</td>\n",
       "      <td>34.953571</td>\n",
       "      <td>48.10</td>\n",
       "      <td>10.10</td>\n",
       "      <td>38.375</td>\n",
       "      <td>-0.041313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105438</td>\n",
       "      <td>0.098850</td>\n",
       "      <td>0.097531</td>\n",
       "      <td>0.105438</td>\n",
       "      <td>0.096344</td>\n",
       "      <td>Alpha1</td>\n",
       "      <td>False</td>\n",
       "      <td>xuan_20919_E2</td>\n",
       "      <td>excitatory</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>8.120000e-11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.022002</td>\n",
       "      <td>0.026474</td>\n",
       "      <td>112.20</td>\n",
       "      <td>46.550000</td>\n",
       "      <td>74.35</td>\n",
       "      <td>13.45</td>\n",
       "      <td>48.475</td>\n",
       "      <td>-0.036437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092062</td>\n",
       "      <td>0.072510</td>\n",
       "      <td>0.086813</td>\n",
       "      <td>0.092062</td>\n",
       "      <td>0.038656</td>\n",
       "      <td>Alpha1</td>\n",
       "      <td>False</td>\n",
       "      <td>xuan_20919_E3</td>\n",
       "      <td>excitatory</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>4.110000e-11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>56.80</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.250</td>\n",
       "      <td>-0.052875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104969</td>\n",
       "      <td>0.098500</td>\n",
       "      <td>0.095438</td>\n",
       "      <td>0.104969</td>\n",
       "      <td>0.095094</td>\n",
       "      <td>D2</td>\n",
       "      <td>False</td>\n",
       "      <td>xuan_22119_E2</td>\n",
       "      <td>inhibitory</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     current_first_spike  ap_count  abs_firing_rate  inst_firing_rate  \\\n",
       "0           1.220000e-10        16         0.032003          0.044065   \n",
       "1           1.220000e-10        12         0.024002          0.031750   \n",
       "2           1.620000e-10        16         0.032003          0.055015   \n",
       "3           1.210000e-10         8         0.016002          0.019330   \n",
       "4           2.020000e-10        51         0.102010          0.102468   \n",
       "..                   ...       ...              ...               ...   \n",
       "138         1.610000e-10         5         0.010001          0.050318   \n",
       "139         8.170000e-11        61         0.122012          0.122809   \n",
       "140         1.220000e-10        15         0.030003          0.034610   \n",
       "141         8.120000e-11        11         0.022002          0.026474   \n",
       "142         4.110000e-11         2         0.004000          0.190476   \n",
       "\n",
       "     time_to_first_spike   mean_isi  max_isi  min_isi  median_isi  first_thrs  \\\n",
       "0                  65.30  29.936667    42.50     8.05      34.450   -0.023906   \n",
       "1                 117.30  43.931818    67.85    11.05      52.700   -0.031313   \n",
       "2                  76.40  28.526667    78.25     8.85      17.700   -0.010969   \n",
       "3                  86.95  61.935714    89.85    22.30      62.800   -0.038187   \n",
       "4                  16.90   9.815000    10.75     6.70       9.900   -0.048063   \n",
       "..                   ...        ...      ...      ...         ...         ...   \n",
       "138                56.00  43.812500    75.90     8.80      45.275   -0.040063   \n",
       "139                17.95   8.190833     8.85     5.30       8.350   -0.055563   \n",
       "140                44.40  34.953571    48.10    10.10      38.375   -0.041313   \n",
       "141               112.20  46.550000    74.35    13.45      48.475   -0.036437   \n",
       "142                56.80   5.250000     5.25     5.25       5.250   -0.052875   \n",
       "\n",
       "     ...  first_amp  mean_amp  median_amp   max_amp   min_amp  \\\n",
       "0    ...   0.111687  0.102479    0.107500  0.111687  0.088250   \n",
       "1    ...   0.095406  0.095406    0.095406  0.095406  0.095406   \n",
       "2    ...   0.109688  0.093625    0.090625  0.109688  0.088063   \n",
       "3    ...   0.083375  0.078828    0.078828  0.083375  0.074281   \n",
       "4    ...   0.100000  0.091615    0.091406  0.100000  0.086031   \n",
       "..   ...        ...       ...         ...       ...       ...   \n",
       "138  ...   0.093062  0.093062    0.093062  0.093062  0.093062   \n",
       "139  ...   0.122219  0.122219    0.122219  0.122219  0.122219   \n",
       "140  ...   0.105438  0.098850    0.097531  0.105438  0.096344   \n",
       "141  ...   0.092062  0.072510    0.086813  0.092062  0.038656   \n",
       "142  ...   0.104969  0.098500    0.095438  0.104969  0.095094   \n",
       "\n",
       "            condtition   drug        exp_name  classification  trial  \n",
       "0                   D2  False  xuan_231018_E1      excitatory      0  \n",
       "1                   D2  False  xuan_231118_E2      excitatory      0  \n",
       "2                   D2  False   xuan_26319_E2      excitatory      0  \n",
       "3                   D2  False   xuan_26319_E4      excitatory      0  \n",
       "4    5HT-1f(S1 cortex)  False   xuan_26619_E6      inhibitory      0  \n",
       "..                 ...    ...             ...             ...    ...  \n",
       "138                 D2  False   xuan_17119_E3      excitatory      0  \n",
       "139             Alpha1  False   xuan_20919_E1      inhibitory      0  \n",
       "140             Alpha1  False   xuan_20919_E2      excitatory      0  \n",
       "141             Alpha1  False   xuan_20919_E3      excitatory      0  \n",
       "142                 D2  False   xuan_22119_E2      inhibitory      0  \n",
       "\n",
       "[143 rows x 29 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n",
    "\n",
    "# exc_inh_df_acsf[exc_inh_df_acsf.exp_name.isin(data['exp_name'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waves_exc = normalize(NC_data1[features_ext_sub][NC_data1.ei_labels == 0])\n",
    "labels_wave_exc,mapper,reducer = plot_UMAP_clusters_single(waves_exc,\n",
    "                          15,\n",
    "                          0.1,\n",
    "                          random_state =42,\n",
    "                          res_louvain = 1,\n",
    "                          c_list =coherence_colors,\n",
    "                          )\n",
    "\n",
    "waves_inh = normalize(NC_data1[features_ext_sub][NC_data1.ei_labels == 1])\n",
    "labels_wave_inh,mapper,reducer = plot_UMAP_clusters_single(waves_inh,\n",
    "                          15,\n",
    "                          0.1,\n",
    "                          random_state =42,\n",
    "                          res_louvain = 1,\n",
    "                          c_list =coherence_colors,\n",
    "                          )                          \n",
    "\n",
    "print(len(NC_data1[features_ext_sub][NC_data1.ei_labels == 1]))\n",
    "\n",
    "print(len(NC_data1[features_ext_sub][NC_data1.ei_labels == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(labels_wave_exc,return_counts=True))\n",
    "print(np.unique(labels_wave_inh,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "waves_exc = normalize(data_exc[feats[:-5]])\n",
    "waves_inh = normalize(data_inh[feats[:-5]])\n",
    "waves_all= normalize(data[feats[:-5]])\n",
    "labels_wave_exc,mapper,reducer = plot_UMAP_clusters_single(waves_exc,\n",
    "                          20,\n",
    "                          0.1,\n",
    "                          random_state =42,\n",
    "                          res_louvain = 1,\n",
    "                          c_list =coherence_colors,\n",
    "                          )\n",
    "\n",
    "labels_wave_inh,mapper,reducer = plot_UMAP_clusters_single(waves_inh,\n",
    "                          20,\n",
    "                          0.1,\n",
    "                          random_state =42,\n",
    "                          res_louvain = 1,\n",
    "                          c_list =coherence_colors,\n",
    "                          )                          \n",
    "\n",
    "print(len(data_inh))\n",
    "\n",
    "print(len(data_exc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution_list = np.linspace(0,5,11)\n",
    "modularity_dict = {}\n",
    "n_clusts_dict = {}\n",
    "#Louvain Clustering Parameters\n",
    "RESOLUTION = 1.5\n",
    "random_state = 42\n",
    "full_data = df_waves_acsf['waveforms']\n",
    "# BLUE COLOR\n",
    "BlueCol = '\\033[94m'\n",
    "subsets=[100]\n",
    "import random \n",
    "for res in resolution_list:\n",
    "    print(\"\\n\" + BlueCol + str(res))\n",
    "    for frac in subsets:\n",
    "        rand_list = []\n",
    "        n_clusts = []\n",
    "        for i in list(range(1,25)):\n",
    "            reducer_rand_test = umap.UMAP(n_neighbors = 20, \n",
    "                                     min_dist=0.0, \n",
    "                                     random_state=random.randint(1,100000))\n",
    "            rand_data = np.vstack(np.random.permutation(full_data))\n",
    "            mapper = reducer_rand_test.fit(rand_data)\n",
    "            embedding_rand_test = reducer_rand_test.transform(rand_data)\n",
    "\n",
    "            umap_df_rand_test = pd.DataFrame(embedding_rand_test, columns=('x', 'y'))\n",
    "            louvain = Louvain(resolution=res,random_state=random_state)\n",
    "            adjacency = mapper.graph_\n",
    "            labels_exc = louvain.fit_predict(adjacency)\n",
    "            clustering_solution = labels_exc\n",
    "            modularity= get_modularity(adjacency,labels_exc)\n",
    "            rand_list.append(modularity)\n",
    "            n_clusts.append(len(set(clustering_solution)))\n",
    "        modularity_dict.update({str(res): rand_list})\n",
    "        n_clusts_dict.update({str(res): n_clusts})\n",
    "\n",
    "\n",
    "resolution_list = np.linspace(0,5,11)\n",
    "\n",
    "if 'n_clusts_dict' not in list(locals().keys()):\n",
    "  n_clusts_dict = pkl.load(open('WaveMAP_Paper/data/n_clusts_dict.pkl','rb'))\n",
    "\n",
    "if 'modularity_dict' not in list(locals().keys()):\n",
    "  modularity_dict = pkl.load(open('WaveMAP_Paper/data/modularity_dict.pkl','rb'))\n",
    "\n",
    "avg_n_clusts = []\n",
    "for k in list(n_clusts_dict.keys()):\n",
    "    avg_n_clusts.append(np.mean(n_clusts_dict[k]))\n",
    "    \n",
    "std_n_clusts = []\n",
    "for k in list(n_clusts_dict.keys()):\n",
    "    std_n_clusts.append(np.std(n_clusts_dict[k]))\n",
    "    \n",
    "std_modularity = []\n",
    "for k in list(modularity_dict.keys()):\n",
    "    std_modularity.append(np.std(modularity_dict[k]))\n",
    "    \n",
    "avg_modularity = []\n",
    "for k in list(modularity_dict.keys()):\n",
    "    avg_modularity.append(np.mean(modularity_dict[k]))\n",
    "\n",
    "f, ax1 = plt.subplots(figsize=[3,2.5])\n",
    "\n",
    "ax1.errorbar(resolution_list,avg_modularity,yerr=std_modularity,\n",
    "             c = '#5c95ff', marker='o', fillstyle='full', markerfacecolor='w', \n",
    "             linewidth=1, markeredgewidth=1)\n",
    "ax1.set_ylabel('Modularity Score')\n",
    "ax1.set_xlabel('Resolution Parameter',fontsize=12)\n",
    "ax1.set_xlim([0,8])\n",
    "ax1.set_xticks([0,2,4,6,8])\n",
    "ax1.yaxis.label.set_color('#5c95ff')\n",
    "ax1.tick_params(axis='y',colors='#5c95ff')\n",
    "ax1.set_ylim(0,1.0)\n",
    "ax1.set_yticks([0,0.2,0.4,0.6,0.8,1.0])\n",
    "# ax1.set_yticklabels([0.0,'',0.2,'',0.4,'',0.6,'',0.8,'',1.0],fontsize=12)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_color('#f87575')\n",
    "ax1.spines['left'].set_color('#5c95ff')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.errorbar(resolution_list[1:],avg_n_clusts[1:],yerr=std_n_clusts[1:],\n",
    "            c = '#f87575', marker='o', fillstyle='full', markerfacecolor='w', linewidth=1, markeredgewidth=1)\n",
    "ax2.set_ylabel('Number of Clusters',fontsize=12,c='#f87575')\n",
    "# ax2.spines['left'].set_color('b')\n",
    "ax2.tick_params(axis='y',colors='#f87575')\n",
    "ax2.set_ylim([0,18])\n",
    "ax2.set_yticks([0,4,8,12,16]);\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_color('#f87575')\n",
    "ax2.spines['left'].set_color('#5c95ff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_umap = exc_inh_df[features_ext_sub][exc_inh_df.ei_labels == 0]\n",
    "data_umap = waves_all\n",
    "cells,features = data_umap.shape\n",
    "pca = PCA(n_components=features)\n",
    "scaler = StandardScaler()\n",
    "data_all = data_umap\n",
    "data_all = scaler.fit_transform(data_all)\n",
    "data_all = normalize(data_all)\n",
    "pca.fit(data_all)\n",
    "eigenvalues = pca.explained_variance_\n",
    "sum(eigenvalues)**2/sum(eigenvalues**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(exc_df_acsf['labels_lv']+1,discrete=True)\n",
    "sns.histplot(exc_df_acsf['labels_lv']+1,discrete=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(len(eigenvalues)),eigenvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def get_confusion_matrix(data,feat):\n",
    "    \n",
    "    testSize = 0.3;\n",
    "    RAND_STATE = 20\n",
    "    UMAP_X = np.stack(data[feat].to_numpy().tolist(), axis=0)\n",
    "    UMAP_y = data['labels_lv'].to_numpy()\n",
    "\n",
    "    unclassified_ixs = [ix for ix,clust in enumerate(UMAP_y) if clust == -1]\n",
    "\n",
    "    UMAP_X = np.delete(UMAP_X,unclassified_ixs,axis=0)\n",
    "    UMAP_y = np.delete(UMAP_y,unclassified_ixs,axis=0)\n",
    "\n",
    "    UMAP_X_train, UMAP_X_test, UMAP_y_train, UMAP_y_test = train_test_split(UMAP_X, UMAP_y, test_size=testSize, random_state=RAND_STATE)\n",
    "\n",
    "\n",
    "    numCV = 5\n",
    "\n",
    "    UMAP_model = xgb.XGBClassifier()\n",
    "    UMAP_param_dist = {\"max_depth\": [4],\n",
    "                \"min_child_weight\" : [2.5],\n",
    "                \"n_estimators\": [100],\n",
    "                \"learning_rate\": [0.3],\n",
    "                \"seed\": [RAND_STATE]}\n",
    "    UMAP_grid_search = GridSearchCV(UMAP_model, param_grid=UMAP_param_dist, \n",
    "                            cv = numCV, \n",
    "                            verbose=10, n_jobs=-1)\n",
    "    UMAP_grid_search.fit(UMAP_X_train, UMAP_y_train)\n",
    "\n",
    "    return  confusion_matrix(UMAP_y_test,UMAP_grid_search.predict(UMAP_X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(conf_matrix,labels):\n",
    "    confusion_mat_counts = conf_matrix\n",
    "    N_CLUST = len(set(labels))\n",
    "    conf_mat_row_list = []\n",
    "    for row in confusion_mat_counts:\n",
    "        row_sum = np.sum(row)\n",
    "        \n",
    "        row_percent = []\n",
    "        \n",
    "        for val in row:\n",
    "            row_percent.append(val/row_sum)\n",
    "        \n",
    "        conf_mat_row_list.append(row_percent)\n",
    "\n",
    "    conf_mat = np.array(conf_mat_row_list)\n",
    "\n",
    "    colormap = mpl.cm.YlGnBu\n",
    "    colormap.set_under('white')\n",
    "\n",
    "    eps = np.spacing(0.0)\n",
    "    f, arr = plt.subplots(1,figsize=[4,3])\n",
    "    mappable = arr.imshow(conf_mat,cmap=colormap,vmin=eps,vmax=1.)\n",
    "    color_bar = f.colorbar(mappable, ax=arr, extend='min')\n",
    "    color_bar.set_label('P (Predicted | True)',fontsize=12,labelpad=15,fontname=\"Arial\")\n",
    "    color_bar.ax.tick_params(size=3,labelsize=12)\n",
    "\n",
    "    #Specify label behavior of the main diagonal\n",
    "    for i in range(0,N_CLUST):\n",
    "        if int(conf_mat[i,i]*100) == 100:\n",
    "            arr.text(i-0.38,i+0.17,int(round(conf_mat[i,i]*100)),fontsize=10,c='white',fontname=\"Arial\")\n",
    "        else:\n",
    "            arr.text(i-0.34,i+0.16,int(round(conf_mat[i,i]*100)),fontsize=10,c='white',fontname=\"Arial\")\n",
    "            \n",
    "    #Specify label behavior of the off-diagonals\n",
    "    for i in range(0,N_CLUST):\n",
    "        for j in range(0,N_CLUST):\n",
    "            if conf_mat[i,j] < 0.1 and conf_mat[i,j] != 0:\n",
    "                arr.text(j-0.2,i+0.15,int(round(conf_mat[i,j]*100)),fontsize=10,c='k',fontname=\"Arial\")\n",
    "            elif conf_mat[i,j] >= 0.1 and conf_mat[i,j] < 0.5 and conf_mat[i,j] != 0:\n",
    "                arr.text(j-0.4, i+0.15,int(round(conf_mat[i,j]*100)),fontsize=10,c='k',fontname=\"Arial\")\n",
    "\n",
    "    arr.set_xticks(range(0,N_CLUST))\n",
    "    arr.set_xticklabels(range(1,N_CLUST+1),fontsize=12);\n",
    "    arr.set_yticks(range(0,N_CLUST))\n",
    "    arr.set_yticklabels(range(1,N_CLUST+1),fontsize=12);\n",
    "    arr.set_xlabel('Predicted Class',fontsize=12);\n",
    "    arr.set_ylabel('True Class',fontsize=12);\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_confusion_matrix(get_confusion_matrix(inh_df_acsf,feat[:-1]),labels_inh)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exc_df_acsf['labels_lv'] = labels_exc\n",
    "\n",
    "plot_confusion_matrix(get_confusion_matrix(exc_df_acsf,feat[:-1]),labels_exc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution_list = np.linspace(0,5,11)\n",
    "modularity_dict = {}\n",
    "n_clusts_dict = {}\n",
    "#Louvain Clustering Parameters\n",
    "RESOLUTION = 1.5\n",
    "random_state = 42\n",
    "full_data = join_wave_with_ephys(feat, exc_inh_df_w_waves_acsf[exc_inh_df_w_waves_acsf['ephys_labels']==0])\n",
    "# BLUE COLOR\n",
    "BlueCol = '\\033[94m'\n",
    "subsets=[100]\n",
    "import random \n",
    "for res in resolution_list:\n",
    "    print(\"\\n\" + BlueCol + str(res))\n",
    "    for frac in subsets:\n",
    "        rand_list = []\n",
    "        n_clusts = []\n",
    "        for i in list(range(1,25)):\n",
    "            reducer_rand_test = umap.UMAP(n_neighbors = 20, \n",
    "                                     min_dist=0.0, \n",
    "                                     random_state=random.randint(1,100000))\n",
    "            rand_data = np.random.permutation(full_data)[0:(int(len(full_data)*frac)),:]\n",
    "            mapper = reducer_rand_test.fit(rand_data)\n",
    "            embedding_rand_test = reducer_rand_test.transform(rand_data)\n",
    "\n",
    "            umap_df_rand_test = pd.DataFrame(embedding_rand_test, columns=('x', 'y'))\n",
    "            louvain = Louvain(resolution=res,random_state=random_state)\n",
    "            adjacency = mapper.graph_\n",
    "            labels_exc = louvain.fit_predict(adjacency)\n",
    "            clustering_solution = labels_exc\n",
    "            modularity= get_modularity(adjacency,labels_exc)\n",
    "            rand_list.append(modularity)\n",
    "            n_clusts.append(len(set(clustering_solution)))\n",
    "        modularity_dict.update({str(res): rand_list})\n",
    "        n_clusts_dict.update({str(res): n_clusts})\n",
    "\n",
    "\n",
    "resolution_list = np.linspace(0,5,11)\n",
    "\n",
    "if 'n_clusts_dict' not in list(locals().keys()):\n",
    "  n_clusts_dict = pkl.load(open('WaveMAP_Paper/data/n_clusts_dict.pkl','rb'))\n",
    "\n",
    "if 'modularity_dict' not in list(locals().keys()):\n",
    "  modularity_dict = pkl.load(open('WaveMAP_Paper/data/modularity_dict.pkl','rb'))\n",
    "\n",
    "avg_n_clusts = []\n",
    "for k in list(n_clusts_dict.keys()):\n",
    "    avg_n_clusts.append(np.mean(n_clusts_dict[k]))\n",
    "    \n",
    "std_n_clusts = []\n",
    "for k in list(n_clusts_dict.keys()):\n",
    "    std_n_clusts.append(np.std(n_clusts_dict[k]))\n",
    "    \n",
    "std_modularity = []\n",
    "for k in list(modularity_dict.keys()):\n",
    "    std_modularity.append(np.std(modularity_dict[k]))\n",
    "    \n",
    "avg_modularity = []\n",
    "for k in list(modularity_dict.keys()):\n",
    "    avg_modularity.append(np.mean(modularity_dict[k]))\n",
    "\n",
    "f, ax1 = plt.subplots(figsize=[3,2.5])\n",
    "\n",
    "ax1.errorbar(resolution_list,avg_modularity,yerr=std_modularity,\n",
    "             c = '#5c95ff', marker='o', fillstyle='full', markerfacecolor='w', \n",
    "             linewidth=1, markeredgewidth=1)\n",
    "ax1.set_ylabel('Modularity Score')\n",
    "ax1.set_xlabel('Resolution Parameter',fontsize=12)\n",
    "ax1.set_xlim([0,8])\n",
    "ax1.set_xticks([0,2,4,6,8])\n",
    "ax1.yaxis.label.set_color('#5c95ff')\n",
    "ax1.tick_params(axis='y',colors='#5c95ff')\n",
    "ax1.set_ylim(0,1.0)\n",
    "ax1.set_yticks([0,0.2,0.4,0.6,0.8,1.0])\n",
    "# ax1.set_yticklabels([0.0,'',0.2,'',0.4,'',0.6,'',0.8,'',1.0],fontsize=12)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_color('#f87575')\n",
    "ax1.spines['left'].set_color('#5c95ff')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.errorbar(resolution_list[1:],avg_n_clusts[1:],yerr=std_n_clusts[1:],\n",
    "            c = '#f87575', marker='o', fillstyle='full', markerfacecolor='w', linewidth=1, markeredgewidth=1)\n",
    "ax2.set_ylabel('Number of Clusters',fontsize=12,c='#f87575')\n",
    "# ax2.spines['left'].set_color('b')\n",
    "ax2.tick_params(axis='y',colors='#f87575')\n",
    "ax2.set_ylim([0,18])\n",
    "ax2.set_yticks([0,4,8,12,16]);\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_color('#f87575')\n",
    "ax2.spines['left'].set_color('#5c95ff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSize = 0.3;\n",
    "\n",
    "UMAP_X = np.stack(umap_df['waveform'].to_numpy().tolist(), axis=0)\n",
    "UMAP_y = umap_df['color'].to_numpy()\n",
    "\n",
    "unclassified_ixs = [ix for ix,clust in enumerate(UMAP_y) if clust == -1]\n",
    "\n",
    "UMAP_X = np.delete(UMAP_X,unclassified_ixs,axis=0)\n",
    "UMAP_y = np.delete(UMAP_y,unclassified_ixs,axis=0)\n",
    "\n",
    "UMAP_X_train, UMAP_X_test, UMAP_y_train, UMAP_y_test = train_test_split(UMAP_X, UMAP_y, test_size=testSize, random_state=RAND)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution_list = np.linspace(0,5,11)\n",
    "modularity_dict = {}\n",
    "n_clusts_dict = {}\n",
    "#Louvain Clustering Parameters\n",
    "RESOLUTION = 1.5\n",
    "random_state = 42\n",
    "full_data = join_wave_with_ephys(feat, exc_inh_df_w_waves_acsf[exc_inh_df_w_waves_acsf['ephys_labels']==1])\n",
    "# BLUE COLOR\n",
    "BlueCol = '\\033[94m'\n",
    "subsets=[100]\n",
    "import random \n",
    "for res in resolution_list:\n",
    "    print(\"\\n\" + BlueCol + str(res))\n",
    "    for frac in subsets:\n",
    "        rand_list = []\n",
    "        n_clusts = []\n",
    "        for i in list(range(1,25)):\n",
    "            reducer_rand_test = umap.UMAP(n_neighbors = 20, \n",
    "                                     min_dist=0.0, \n",
    "                                     random_state=random.randint(1,100000))\n",
    "            rand_data = np.random.permutation(full_data)[0:(int(len(full_data)*frac)),:]\n",
    "            mapper = reducer_rand_test.fit(rand_data)\n",
    "            embedding_rand_test = reducer_rand_test.transform(rand_data)\n",
    "\n",
    "            umap_df_rand_test = pd.DataFrame(embedding_rand_test, columns=('x', 'y'))\n",
    "            louvain = Louvain(resolution=res,random_state=random_state)\n",
    "            adjacency = mapper.graph_\n",
    "            labels_exc = louvain.fit_predict(adjacency)\n",
    "            clustering_solution = labels_exc\n",
    "            modularity= get_modularity(adjacency,labels_exc)\n",
    "            rand_list.append(modularity)\n",
    "            n_clusts.append(len(set(clustering_solution)))\n",
    "        modularity_dict.update({str(res): rand_list})\n",
    "        n_clusts_dict.update({str(res): n_clusts})\n",
    "\n",
    "\n",
    "resolution_list = np.linspace(0,5,11)\n",
    "\n",
    "if 'n_clusts_dict' not in list(locals().keys()):\n",
    "  n_clusts_dict = pkl.load(open('WaveMAP_Paper/data/n_clusts_dict.pkl','rb'))\n",
    "\n",
    "if 'modularity_dict' not in list(locals().keys()):\n",
    "  modularity_dict = pkl.load(open('WaveMAP_Paper/data/modularity_dict.pkl','rb'))\n",
    "\n",
    "avg_n_clusts = []\n",
    "for k in list(n_clusts_dict.keys()):\n",
    "    avg_n_clusts.append(np.mean(n_clusts_dict[k]))\n",
    "    \n",
    "std_n_clusts = []\n",
    "for k in list(n_clusts_dict.keys()):\n",
    "    std_n_clusts.append(np.std(n_clusts_dict[k]))\n",
    "    \n",
    "std_modularity = []\n",
    "for k in list(modularity_dict.keys()):\n",
    "    std_modularity.append(np.std(modularity_dict[k]))\n",
    "    \n",
    "avg_modularity = []\n",
    "for k in list(modularity_dict.keys()):\n",
    "    avg_modularity.append(np.mean(modularity_dict[k]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax1 = plt.subplots(figsize=[3,2.5])\n",
    "\n",
    "ax1.errorbar(resolution_list,avg_modularity,yerr=std_modularity,\n",
    "             c = '#5c95ff', marker='o', fillstyle='full', markerfacecolor='w', \n",
    "             linewidth=1, markeredgewidth=1)\n",
    "ax1.set_ylabel('Modularity Score')\n",
    "ax1.set_xlabel('Resolution Parameter',fontsize=12)\n",
    "ax1.set_xlim([0,8])\n",
    "ax1.set_xticks([0,1,2,4,6,8])\n",
    "ax1.yaxis.label.set_color('#5c95ff')\n",
    "ax1.tick_params(axis='y',colors='#5c95ff')\n",
    "ax1.set_ylim(0,1.0)\n",
    "ax1.set_yticks([0,0.2,0.4,0.6,0.8,1.0])\n",
    "# ax1.set_yticklabels([0.0,'',0.2,'',0.4,'',0.6,'',0.8,'',1.0],fontsize=12)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_color('#f87575')\n",
    "ax1.spines['left'].set_color('#5c95ff')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.errorbar(resolution_list[1:],avg_n_clusts[1:],yerr=std_n_clusts[1:],\n",
    "            c = '#f87575', marker='o', fillstyle='full', markerfacecolor='w', linewidth=1, markeredgewidth=1)\n",
    "ax2.set_ylabel('Number of Clusters',fontsize=12,c='#f87575')\n",
    "# ax2.spines['left'].set_color('b')\n",
    "ax2.tick_params(axis='y',colors='#f87575')\n",
    "ax2.set_ylim([0,18])\n",
    "ax2.set_yticks([0,4,8,12,16]);\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_color('#f87575')\n",
    "ax2.spines['left'].set_color('#5c95ff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.plotting_context(rc={\"axes.labelsize\":20}):\n",
    "    sns.pairplot(inh_df_acsf[['AP_avg','resistance','ap_width','thr','isi', 'sub_thr', 'imp','labels_lv']],hue='labels_lv',palette=CUSTOM_PAL_SORT_3[:len(set(inh_df_acsf['labels_lv']))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.plotting_context(rc={\"axes.labelsize\":20}):\n",
    "    sns.pairplot(exc_df_acsf[['AP_avg','resistance','ap_width','thr','isi', 'sub_thr', 'imp','labels_lv']],hue='labels_lv',palette=CUSTOM_PAL_SORT_3[:len(set(exc_df_acsf['labels_lv']))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "def get_pvalues(data,var,hue):\n",
    "    df = data\n",
    "    x = hue\n",
    "    y = var\n",
    "\n",
    "    pairs = np.unique(data[hue])\n",
    "    pairs = [i for i in combinations(pairs,2)]\n",
    "    test_short_name = 'Mann-Whitney'\n",
    "    pvalues = []\n",
    "    sigs = []\n",
    "    for pair in pairs:\n",
    "        data1 = df.groupby(x)[y].get_group(pair[0])\n",
    "        data2 = df.groupby(x)[y].get_group(pair[1])\n",
    "        stat, p = mannwhitneyu(data1, data2)\n",
    "        pvalues.append(p)\n",
    "\n",
    "        if  p > 5.00e-02 and p <= 1.00e+00:\n",
    "            sigs.append(0)\n",
    "        elif 1.00e-02 < p and p <= 5.00e-02:\n",
    "            sigs.append(1)\n",
    "        elif 1.00e-03 < p and p<= 1.00e-02:\n",
    "            sigs.append(2)\n",
    "        elif 1.00e-04 < p and p<= 1.00e-03:\n",
    "            sigs.append(3)   \n",
    "        elif  p <= 1.00e-04:\n",
    "            sigs.append(4)   \n",
    "\n",
    "    sig_matrix = np.zeros((len(set(data.labels_lv)),len(set(data.labels_lv))))\n",
    "    for i,j in enumerate(pairs):\n",
    "        sig_matrix[j] = sigs[i]\n",
    "    sig_matrix = sig_matrix+sig_matrix.T     \n",
    "    return sig_matrix# pvalues,pairs,sigs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from statannotations.Annotator import Annotator\n",
    "def plot_significance_new(data,var,hue,ax,palette='mako',drug=False,test ='Mann-Whitney'):\n",
    "\n",
    "\n",
    "    ax.tick_params(axis='x', labelsize=20)\n",
    "    ax.tick_params(axis='y', labelsize=20)\n",
    "\n",
    "    boxes = sns.violinplot(data=data,\n",
    "                            x=hue,\n",
    "                            y=var,\n",
    "                            width=.6, \n",
    "                            palette=palette,\n",
    "                            ax=ax)\n",
    "\n",
    "    # sns.stripplot(x=hue, y=var , data=data,           \n",
    "    #             size=3, color=\".4\", linewidth=0,ax=ax) \n",
    "    ax.set_xlabel('class',fontdict={'fontsize':20})\n",
    "    ax.set_ylabel(var,fontdict={'fontsize':20})\n",
    "\n",
    "    for box,col in zip(boxes.patches,['blue','crimson','teal']):\n",
    "        mybox1 = box\n",
    "\n",
    "        # Change the appearance of that box\n",
    "        if drug:\n",
    "            mybox1.set_facecolor('white')\n",
    "            mybox1.set_edgecolor(col)\n",
    "        else:\n",
    "            mybox1.set_facecolor(col)\n",
    "            mybox1.set_edgecolor('black')\n",
    "\n",
    "        mybox1.set_linewidth(3)\n",
    "\n",
    "    pairs = np.unique(data[hue])\n",
    "    pairs = [i for i in combinations(pairs,2)]\n",
    "\n",
    "    annotator = Annotator(ax,pairs, data=data, x=hue,palette=palette, y=var)\n",
    "    annotator.configure(test=test, text_format='star', loc='inside')\n",
    "    annotator.apply_and_annotate()  \n",
    "    plt.show()\n",
    "\n",
    "for val in ['AP_avg','ap_width', 'resistance','mi', 'thr', 'isi', 'sub_thr','imp']:\n",
    "\n",
    "    fig,ax = plt.subplots(1,1,figsize=[10,10])\n",
    "\n",
    "    plot_significance_new(data = inh_df_acsf,\n",
    "    var = val,\n",
    "    hue = 'labels_lv',\n",
    "    ax = ax,\n",
    "    drug = False,\n",
    "    palette = CUSTOM_PAL_SORT_3[:len(set(exc_df_acsf['labels_lv']))] )\n",
    "    # plt.savefig('C:/Users/Nishant Joshi/Documents/DNM/'+val+'_'+cond+'_dist.png',dpi=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_all_inh = []\n",
    "for val in ['AP_avg','ap_width', 'resistance','mi', 'thr', 'isi', 'sub_thr','imp']:    \n",
    "    sig_matrix = get_pvalues(inh_df_acsf,var = val,hue = 'labels_lv',)\n",
    "    sig_all_inh.append(sig_matrix)\n",
    "    fig,ax = plt.subplots(1,1,figsize=[4,4])\n",
    "    sns.heatmap(sig_matrix,annot=True,ax=ax)\n",
    "    ax.set_title(val+' significance')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_inh = np.zeros_like(sig_all_inh[0])\n",
    "for i in np.arange(len(sig_all_inh)):\n",
    "    a_inh += sig_all_inh[i]\n",
    "sns.heatmap(a_inh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from statannotations.Annotator import Annotator\n",
    "\n",
    "def plot_significance_new(data,var,hue,ax,palette='mako',drug=False,test ='Mann-Whitney'):\n",
    "    ax.tick_params(axis='x', labelsize=20)\n",
    "    ax.tick_params(axis='y', labelsize=20)\n",
    "\n",
    "    boxes = sns.violinplot(data=data,\n",
    "                x=hue,\n",
    "                y=var,\n",
    "                width=.6, \n",
    "                palette=palette,\n",
    "                ax=ax)\n",
    "                          \n",
    "    # sns.stripplot(x=hue, y=var , data=data,\n",
    "    #             size=3, color=\".4\", linewidth=0,ax=ax)\n",
    "    ax.set_xlabel('class',fontdict={'fontsize':20})\n",
    "    ax.set_ylabel(var,fontdict={'fontsize':20})\n",
    "\n",
    "    for box,col in zip(boxes.patches,['blue','crimson','teal']):\n",
    "        mybox1 = box\n",
    "\n",
    "        # Change the appearance of that box\n",
    "        if drug:\n",
    "            mybox1.set_facecolor('white')\n",
    "            mybox1.set_edgecolor(col)\n",
    "        else:\n",
    "            mybox1.set_facecolor(col)\n",
    "            mybox1.set_edgecolor('black')\n",
    "\n",
    "        mybox1.set_linewidth(3)\n",
    "\n",
    "    pairs = np.unique(data[hue])\n",
    "    pairs = [i for i in combinations(pairs,2)]\n",
    "\n",
    "\n",
    "    annotator = Annotator(ax,pairs, data=data, x=hue,palette=palette, y=var)\n",
    "    annotator.configure(test=test, text_format='star', loc='inside')\n",
    "    annotator.apply_and_annotate()  \n",
    "\n",
    "for val in ['AP_avg', 'ap_width','resistance','mi', 'thr', 'isi', 'sub_thr','imp']:\n",
    "    fig,ax = plt.subplots(1,1,figsize=[10,10])\n",
    "    plot_significance_new(data = exc_df_acsf,\n",
    "    var = val,\n",
    "    hue = 'labels_lv',\n",
    "    ax = ax,\n",
    "    drug = False,\n",
    "    palette = CUSTOM_PAL_SORT_3[:len(set(exc_df_acsf['labels_lv']))])\n",
    "    # plt.savefig('C:/Users/Nishant Joshi/Documents/DNM/'+val+'_'+cond+'_dist.png',dpi=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_all_exc = []\n",
    "for val in ['AP_avg','ap_width', 'resistance','mi', 'thr', 'isi', 'sub_thr','imp']:    \n",
    "    sig_matrix = get_pvalues(exc_df_acsf,var = val,hue = 'labels_lv',)\n",
    "    sig_all_exc.append(sig_matrix)\n",
    "    fig,ax = plt.subplots(1,1,figsize=[4,4])\n",
    "    sns.heatmap(sig_matrix,annot=True,ax=ax)\n",
    "    ax.set_title(val+' significance')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_exc = np.zeros_like(sig_all[0])\n",
    "for i in np.arange(len(sig_all)):\n",
    "    a_exc += sig_all_exc[i]\n",
    "sns.heatmap(a_exc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
